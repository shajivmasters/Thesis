{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b7228b",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Predictions:\n",
      "{\n",
      "    \"sequence\": \"I'm having trouble with my internet connection.\",\n",
      "    \"labels\": [\n",
      "        \"General Inquiry\",\n",
      "        \"Billing Inquiry\",\n",
      "        \"Service Complaint\",\n",
      "        \"Technical Support\"\n",
      "    ],\n",
      "    \"scores\": [\n",
      "        0.33063021302223206,\n",
      "        0.23186515271663666,\n",
      "        0.22003042697906494,\n",
      "        0.21747422218322754\n",
      "    ]\n",
      "}\n",
      "\n",
      "RoBERTa Predictions:\n",
      "{\n",
      "    \"sequence\": \"I'm having trouble with my internet connection.\",\n",
      "    \"labels\": [\n",
      "        \"Technical Support\",\n",
      "        \"Service Complaint\",\n",
      "        \"Billing Inquiry\",\n",
      "        \"General Inquiry\"\n",
      "    ],\n",
      "    \"scores\": [\n",
      "        0.2516486644744873,\n",
      "        0.2500995695590973,\n",
      "        0.24931930005550385,\n",
      "        0.24893245100975037\n",
      "    ]\n",
      "}\n",
      "Best BERT Prediction: General Inquiry\n",
      "Best RoBERTa Prediction: Technical Support\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "# Initialize zero-shot classification pipelines for BERT and RoBERTa\n",
    "bert_classifier = pipeline(\"zero-shot-classification\", model=\"bert-base-uncased\")\n",
    "roberta_classifier = pipeline(\"zero-shot-classification\", model=\"roberta-base\")\n",
    "\n",
    "# Sample text\n",
    "text = \"I'm having trouble with my internet connection.\"\n",
    "\n",
    "# Candidate labels (intents)\n",
    "candidate_labels = [\"Technical Support\", \"Billing Inquiry\", \"Service Complaint\", \"General Inquiry\"]\n",
    "\n",
    "# Perform zero-shot classification with BERT\n",
    "bert_predictions = bert_classifier(text, candidate_labels)\n",
    "\n",
    "# Perform zero-shot classification with RoBERTa\n",
    "roberta_predictions = roberta_classifier(text, candidate_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"BERT Predictions:\")\n",
    "print(json.dumps(bert_predictions,indent=4))\n",
    "\n",
    "print(\"\\nRoBERTa Predictions:\")\n",
    "print(json.dumps(roberta_predictions,indent=4))\n",
    "\n",
    "# Get the best prediction for BERT\n",
    "best_bert_prediction = max(bert_predictions[\"scores\"])\n",
    "best_bert_label = bert_predictions[\"labels\"][bert_predictions[\"scores\"].index(best_bert_prediction)]\n",
    "\n",
    "# Get the best prediction for RoBERTa\n",
    "best_roberta_prediction = max(roberta_predictions[\"scores\"])\n",
    "best_roberta_label = roberta_predictions[\"labels\"][roberta_predictions[\"scores\"].index(best_roberta_prediction)]\n",
    "\n",
    "# Print the best predictions\n",
    "print(\"Best BERT Prediction:\", best_bert_label)\n",
    "print(\"Best RoBERTa Prediction:\", best_roberta_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208f0b78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating RoBERTa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating SBERT...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8238dc57916c4fc38fa4bbb1552162ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9d2d61d0a94a5cb97841d138f57ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6b9665b52f4c01837734cc901e5130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7304a3daf4c84a0abb575d50c056d6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a81568e6724e5aad57e5bd0d20901b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ce2e71184747d197f3a8a656b07f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Accuracy  Precision  Recall  F1-score  Time taken\n",
      "0     BERT      0.17   0.193575    0.17  0.087747   59.506135\n",
      "1  RoBERTa      0.21   0.086684    0.21  0.119684   63.319368\n",
      "2    SBERT      0.24   0.243208    0.24  0.207631    8.992744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Length of IterableDataset\")\n",
    "\n",
    "# Load the dataset from CSV\n",
    "dataset = pd.read_csv(\"customer_support_tickets.csv\")\n",
    "# Load the dataset from CSV\n",
    "\n",
    "\n",
    "# Select a subset of 100 samples\n",
    "subset = dataset.sample(n=100, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"RoBERTa\": \"roberta-base\",\n",
    "    \"SBERT\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store metrics\n",
    "metrics_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time taken\"])\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating {model_name}...\")\n",
    "    \n",
    "    # Initialize zero-shot classification pipeline\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=model)\n",
    "    \n",
    "    # Extract ticket descriptions and true labels from the subset\n",
    "    texts = subset[\"Ticket Description\"].tolist()\n",
    "    true_labels = subset[\"Ticket Type\"].tolist()\n",
    "    \n",
    "    # Candidate labels (intents) - assuming unique ticket types are the labels\n",
    "    candidate_labels = subset[\"Ticket Type\"].unique().tolist()\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform zero-shot classification\n",
    "    predictions = classifier(texts, candidate_labels=candidate_labels, multi_label=False)\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Extract predicted labels\n",
    "    predicted_labels = [prediction['labels'][0] for prediction in predictions]\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Append metrics to DataFrame\n",
    "    metrics_df = metrics_df.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"Time taken\": duration\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Print the metrics DataFrame\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99fee7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
