{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a7b4ef",
   "metadata": {},
   "source": [
    "### Testing for Zero shot pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b7228b",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Predictions:\n",
      "{\n",
      "    \"sequence\": \"I'm having trouble with my internet connection.\",\n",
      "    \"labels\": [\n",
      "        \"General Inquiry\",\n",
      "        \"Billing Inquiry\",\n",
      "        \"Service Complaint\",\n",
      "        \"Technical Support\"\n",
      "    ],\n",
      "    \"scores\": [\n",
      "        0.33063021302223206,\n",
      "        0.23186515271663666,\n",
      "        0.22003042697906494,\n",
      "        0.21747422218322754\n",
      "    ]\n",
      "}\n",
      "\n",
      "RoBERTa Predictions:\n",
      "{\n",
      "    \"sequence\": \"I'm having trouble with my internet connection.\",\n",
      "    \"labels\": [\n",
      "        \"Technical Support\",\n",
      "        \"Service Complaint\",\n",
      "        \"Billing Inquiry\",\n",
      "        \"General Inquiry\"\n",
      "    ],\n",
      "    \"scores\": [\n",
      "        0.2516486644744873,\n",
      "        0.2500995695590973,\n",
      "        0.24931930005550385,\n",
      "        0.24893245100975037\n",
      "    ]\n",
      "}\n",
      "Best BERT Prediction: General Inquiry\n",
      "Best RoBERTa Prediction: Technical Support\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "# Initialize zero-shot classification pipelines for BERT and RoBERTa\n",
    "bert_classifier = pipeline(\"zero-shot-classification\", model=\"bert-base-uncased\")\n",
    "roberta_classifier = pipeline(\"zero-shot-classification\", model=\"roberta-base\")\n",
    "\n",
    "# Sample text\n",
    "text = \"I'm having trouble with my internet connection.\"\n",
    "\n",
    "# Candidate labels (intents)\n",
    "candidate_labels = [\"Technical Support\", \"Billing Inquiry\", \"Service Complaint\", \"General Inquiry\"]\n",
    "\n",
    "# Perform zero-shot classification with BERT\n",
    "bert_predictions = bert_classifier(text, candidate_labels)\n",
    "\n",
    "# Perform zero-shot classification with RoBERTa\n",
    "roberta_predictions = roberta_classifier(text, candidate_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"BERT Predictions:\")\n",
    "print(json.dumps(bert_predictions,indent=4))\n",
    "\n",
    "print(\"\\nRoBERTa Predictions:\")\n",
    "print(json.dumps(roberta_predictions,indent=4))\n",
    "\n",
    "# Get the best prediction for BERT\n",
    "best_bert_prediction = max(bert_predictions[\"scores\"])\n",
    "best_bert_label = bert_predictions[\"labels\"][bert_predictions[\"scores\"].index(best_bert_prediction)]\n",
    "\n",
    "# Get the best prediction for RoBERTa\n",
    "best_roberta_prediction = max(roberta_predictions[\"scores\"])\n",
    "best_roberta_label = roberta_predictions[\"labels\"][roberta_predictions[\"scores\"].index(best_roberta_prediction)]\n",
    "\n",
    "# Print the best predictions\n",
    "print(\"Best BERT Prediction:\", best_bert_label)\n",
    "print(\"Best RoBERTa Prediction:\", best_roberta_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886ae37",
   "metadata": {},
   "source": [
    "### Test with 100 datapoint with 3 model only just to have a quick view "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208f0b78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating RoBERTa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating SBERT...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8238dc57916c4fc38fa4bbb1552162ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9d2d61d0a94a5cb97841d138f57ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6b9665b52f4c01837734cc901e5130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7304a3daf4c84a0abb575d50c056d6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a81568e6724e5aad57e5bd0d20901b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ce2e71184747d197f3a8a656b07f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Accuracy  Precision  Recall  F1-score  Time taken\n",
      "0     BERT      0.17   0.193575    0.17  0.087747   59.506135\n",
      "1  RoBERTa      0.21   0.086684    0.21  0.119684   63.319368\n",
      "2    SBERT      0.24   0.243208    0.24  0.207631    8.992744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Length of IterableDataset\")\n",
    "\n",
    "# Load the dataset from CSV\n",
    "dataset = pd.read_csv(\"customer_support_tickets.csv\")\n",
    "# Load the dataset from CSV\n",
    "\n",
    "\n",
    "# Select a subset of 100 samples\n",
    "subset = dataset.sample(n=100, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"RoBERTa\": \"roberta-base\",\n",
    "    \"SBERT\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store metrics\n",
    "metrics_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time taken\"])\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating {model_name}...\")\n",
    "    \n",
    "    # Initialize zero-shot classification pipeline\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=model)\n",
    "    \n",
    "    # Extract ticket descriptions and true labels from the subset\n",
    "    texts = subset[\"Ticket Description\"].tolist()\n",
    "    true_labels = subset[\"Ticket Type\"].tolist()\n",
    "    \n",
    "    # Candidate labels (intents) - assuming unique ticket types are the labels\n",
    "    candidate_labels = subset[\"Ticket Type\"].unique().tolist()\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform zero-shot classification\n",
    "    predictions = classifier(texts, candidate_labels=candidate_labels, multi_label=False)\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Extract predicted labels\n",
    "    predicted_labels = [prediction['labels'][0] for prediction in predictions]\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Append metrics to DataFrame\n",
    "    metrics_df = metrics_df.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"Time taken\": duration\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Print the metrics DataFrame\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b67547",
   "metadata": {},
   "source": [
    "### Test with 100 datapoint with 9 model only just to have a quick view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99fee7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating RoBERTa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating SBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating XLNet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8a655950d54f50aaad5e6f2d445b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d51b4d3f6834fa386643e3d87cd3f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c70cdab9cb94f6ca54d5714ee444474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963ca41a7cfd425685aad5742d07033c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating DistilBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating ALBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Electra...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b97ad7b5b945aab4d7a7ebb43180e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff69963b984244eab9dd57de28634eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da154e0450924a1887a22533812efc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e583a9a46a54faead226febeb42f4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8445a5c1fb44777ac4d8839d8285d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating GPT-2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c48b27bc69a4e44a16c5708c0a98140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9fe7718ac34c009a30fc0843d57b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc3129eea394867872bf54e7dbb3ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde913b3d0394a8cadc64350e0fd8557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0434301bae354809890c30506aa450f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03679e20d71411ab8044ce24a7554d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Tokenizer was not supporting padding necessary for zero-shot, attempting to use  `pad_token=eos_token`\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating T5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bc14ee54ee4e07aa7da18aae6ee4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a6890714e940d1ad15475226d7e679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at t5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300eb13dccdc4a87a97eb05fb62cb30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1a2b3bd6984cb99b75b3dcd5f48dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model  Accuracy  Precision  Recall  F1-score  Time taken\n",
      "0        BERT      0.20   0.233477    0.20  0.134553   47.856331\n",
      "1     RoBERTa      0.25   0.105000    0.25  0.130286   49.809778\n",
      "2       SBERT      0.14   0.050000    0.14  0.063846   10.026513\n",
      "3       XLNet      0.21   0.116282    0.21  0.127258   83.101644\n",
      "4  DistilBERT      0.21   0.087683    0.21  0.114476   17.317916\n",
      "5      ALBERT      0.18   0.178392    0.18  0.170265   30.024693\n",
      "6     Electra      0.21   0.083936    0.21  0.094188   25.235507\n",
      "7       GPT-2      0.14   0.136278    0.14  0.090994   26.970650\n",
      "8          T5      0.20   0.387683    0.20  0.118937  118.375080\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset from CSV\n",
    "dataset = pd.read_csv(\"customer_support_tickets.csv\")\n",
    "\n",
    "# Select a subset of 100 samples\n",
    "subset = dataset.sample(n=100, random_state=42)\n",
    "\n",
    "# Define the models for comparison\n",
    "models = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"RoBERTa\": \"roberta-base\",\n",
    "    \"SBERT\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "    \"XLNet\": \"xlnet-base-cased\",\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
    "    \"ALBERT\": \"albert-base-v2\",\n",
    "    \"Electra\": \"google/electra-base-discriminator\",\n",
    "    \"GPT-2\": \"gpt2\",\n",
    "    \"T5\": \"t5-base\",\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store metrics\n",
    "metrics_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time taken\"])\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating {model_name}...\")\n",
    "    \n",
    "    # Initialize zero-shot classification pipeline\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=model)\n",
    "    \n",
    "    # Extract ticket descriptions and true labels from the subset\n",
    "    texts = subset[\"Ticket Description\"].tolist()\n",
    "    true_labels = subset[\"Ticket Type\"].tolist()\n",
    "    \n",
    "    # Candidate labels (intents) - assuming unique ticket types are the labels\n",
    "    candidate_labels = subset[\"Ticket Type\"].unique().tolist()\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform zero-shot classification\n",
    "    predictions = classifier(texts, candidate_labels=candidate_labels, multi_label=False)\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Extract predicted labels\n",
    "    predicted_labels = [prediction['labels'][0] for prediction in predictions]\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Append metrics to DataFrame\n",
    "    metrics_df = metrics_df.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"Time taken\": duration\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Print the metrics DataFrame\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5519ff55",
   "metadata": {},
   "source": [
    "### Test with full  datapoint(8000*) with 9 model to have a full view "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731568bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 13:26:08.450114: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BERT...\n",
      "\n",
      "Evaluating RoBERTa...\n",
      "Evaluating SBERT...\n",
      "\n",
      "Evaluating XLNet...\n",
      "\n",
      "\n",
      "Evaluating DistilBERT...\n",
      "\n",
      "Evaluating ALBERT...\n",
      "\n",
      "Evaluating Electra...\n",
      "\n",
      "Evaluating GPT-2...\n",
      "Evaluating T5...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Tokenizer was not supporting padding necessary for zero-shot, attempting to use  `pad_token=eos_token`\n",
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at t5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for SBERT:\n",
      "Accuracy: 0.18845200141693233\n",
      "Precision: 0.23351400361525787\n",
      "Recall: 0.18845200141693233\n",
      "F1-score: 0.11970813721613355\n",
      "Time taken: 6498.826976060867 seconds\n",
      "\n",
      "Metrics for DistilBERT:\n",
      "Accuracy: 0.206163655685441\n",
      "Precision: 0.2661173578462602\n",
      "Recall: 0.206163655685441\n",
      "F1-score: 0.08052266740891438\n",
      "Time taken: 9972.261229991913 seconds\n",
      "\n",
      "Metrics for Electra:\n",
      "Accuracy: 0.2038021017829732\n",
      "Precision: 0.2074110853064702\n",
      "Recall: 0.2038021017829732\n",
      "F1-score: 0.1556103342464754\n",
      "Time taken: 17547.84075808525 seconds\n",
      "\n",
      "Metrics for BERT:\n",
      "Accuracy: 0.1970716731609399\n",
      "Precision: 0.16653531401767593\n",
      "Recall: 0.1970716731609399\n",
      "F1-score: 0.1511419893092956\n",
      "Time taken: 17538.676689863205 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for RoBERTa:\n",
      "Accuracy: 0.19553666312433582\n",
      "Precision: 0.10958946076281297\n",
      "Recall: 0.19553666312433582\n",
      "F1-score: 0.1209602798150657\n",
      "Time taken: 17611.67304778099 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for GPT-2:\n",
      "Accuracy: 0.1996693824536545\n",
      "Precision: 0.1635266707660979\n",
      "Recall: 0.1996693824536545\n",
      "F1-score: 0.1453089680337354\n",
      "Time taken: 18830.012189149857 seconds\n",
      "\n",
      "Metrics for ALBERT:\n",
      "Accuracy: 0.20663596646593457\n",
      "Precision: 0.20044928233279574\n",
      "Recall: 0.20663596646593457\n",
      "F1-score: 0.1761370229096668\n",
      "Time taken: 19803.98435997963 seconds\n",
      "\n",
      "Metrics for XLNet:\n",
      "Accuracy: 0.19813437241705043\n",
      "Precision: 0.16141832203625053\n",
      "Recall: 0.19813437241705043\n",
      "F1-score: 0.1526886537036815\n",
      "Time taken: 20270.039855241776 seconds\n",
      "\n",
      "Metrics for T5:\n",
      "Accuracy: 0.20002361553902467\n",
      "Precision: 0.22927261620020847\n",
      "Recall: 0.20002361553902467\n",
      "F1-score: 0.15541347461183408\n",
      "Time taken: 22553.640382766724 seconds\n",
      "\n",
      "Final Metrics DataFrame:\n",
      "        Model  Accuracy  Precision    Recall  F1-score    Time taken\n",
      "0        BERT  0.197072   0.166535  0.197072  0.151142  17538.676690\n",
      "1     RoBERTa  0.195537   0.109589  0.195537  0.120960  17611.673048\n",
      "2       SBERT  0.188452   0.233514  0.188452  0.119708   6498.826976\n",
      "3       XLNet  0.198134   0.161418  0.198134  0.152689  20270.039855\n",
      "4  DistilBERT  0.206164   0.266117  0.206164  0.080523   9972.261230\n",
      "5      ALBERT  0.206636   0.200449  0.206636  0.176137  19803.984360\n",
      "6     Electra  0.203802   0.207411  0.203802  0.155610  17547.840758\n",
      "7       GPT-2  0.199669   0.163527  0.199669  0.145309  18830.012189\n",
      "8          T5  0.200024   0.229273  0.200024  0.155413  22553.640383\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Length of IterableDataset\")\n",
    "\n",
    "\n",
    "# Define the function to evaluate a single model\n",
    "def evaluate_model(model_name, model, subset):\n",
    "    print(f\"Evaluating {model_name}...\\n\")\n",
    "    \n",
    "    # Initialize zero-shot classification pipeline\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=model)\n",
    "    \n",
    "    # Extract ticket descriptions and true labels from the subset\n",
    "    texts = subset[\"Ticket Description\"].tolist()\n",
    "    true_labels = subset[\"Ticket Type\"].tolist()\n",
    "    \n",
    "    # Candidate labels (intents) - assuming unique ticket types are the labels\n",
    "    candidate_labels = subset[\"Ticket Type\"].unique().tolist()\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform zero-shot classification\n",
    "    predictions = classifier(texts, candidate_labels=candidate_labels, multi_label=False)\n",
    "    \n",
    "    # Measure the time taken for classification\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Extract predicted labels\n",
    "    predicted_labels = [prediction['labels'][0] for prediction in predictions]\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Print the metrics for this model\n",
    "    print(f\"\\nMetrics for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(f\"Time taken: {duration} seconds\")\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"Time taken\": duration\n",
    "    }\n",
    "\n",
    "# Load the dataset from CSV\n",
    "subset = pd.read_csv(\"customer_support_tickets.csv\")\n",
    "\n",
    "# Define the models for comparison\n",
    "models = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"RoBERTa\": \"roberta-base\",\n",
    "    \"SBERT\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "    \"XLNet\": \"xlnet-base-cased\",\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
    "    \"ALBERT\": \"albert-base-v2\",\n",
    "    \"Electra\": \"google/electra-base-discriminator\",\n",
    "    \"GPT-2\": \"gpt2\",\n",
    "    \"T5\": \"t5-base\"\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Initialize ThreadPoolExecutor\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Submit tasks for each model\n",
    "    futures = {model_name: executor.submit(evaluate_model, model_name, model, subset) for model_name, model in models.items()}\n",
    "    \n",
    "    # Collect and print results as they complete\n",
    "    for model_name, future in futures.items():\n",
    "        result = future.result()\n",
    "        results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "metrics_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the final metrics DataFrame\n",
    "print(\"\\nFinal Metrics DataFrame:\")\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0418f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
